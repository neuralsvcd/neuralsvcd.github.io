<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />

  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">

  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <meta name="twitter:card" content="summary_large_image">

  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="src/css/bulma.min.css">
  <link rel="stylesheet" href="src/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="src/css/bulma-slider.min.css">
  <link rel="stylesheet" href="src/css/viewer.css">
  <!-- <link rel="stylesheet" href="src/css/fontawesome.all.min.css"> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="src/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <!-- <script defer src="src/fontawesome.all.min.js"></script> -->
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script type="module" src="./src/redirect.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">NeuralSVCD for Efficient Swept Volume Collision Detection</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Anonymous Author(s)</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block">Affiliation<br>CoRL 2025</span>
              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>
            <!-- <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div> -->
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Robot manipulation in unstructured environments requires efficient and reliable Swept Volume Collision Detection (SVCD) for safe motion planning.
              Traditional discrete methods potentially miss collisions between these points, whereas SVCD continuously checks for collisions along the entire trajectory.
              Existing SVCD methods typically face a trade-off between efficiency and accuracy, limiting practical use.
              In this paper, we introduce NeuralSVCD, a novel neural encoder-decoder architecture tailored to overcome this trade-off.
              Our approach leverages shape locality and temporal locality through distributed geometric representations and temporal optimization.
              This enhances computational efficiency without sacrificing accuracy.
              Comprehensive experiments show that NeuralSVCD consistently outperforms existing state-of-the-art SVCD methods in terms of both collision detection accuracy and computational efficiency, demonstrating its robust applicability across diverse robotic manipulation scenarios.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
            <p>
              NeuralSVCD is a SVCD(Swept Volume Collision Detection) algorithm which
              uses a novel geometric representation designed to leverage shape locality and temporal locality,
              which has 24 times speed-up over sphere-based GPU methods (collision detector from cuRobo) and
              more than a 100 times speed-up over mesh-based GJK (collision detector from TrajOpt)
              —while simultaneously improving accuracy by ≈ 5~15 % even with the shapes unseen during.
              Our method consists of three stages: object encoding, broad phase, and narrow phase.
            </p>
            <img src="src/images/inference.png" alt="Inference Pipeline" />
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-centered has-text-centered">
        <h2 class="title is-4">Object Encoding</h2>
        <div class="columns is-centered">
          <div class="column is-four-fifths has-text-justified">
            <p>
              In the object encoding stage, we encode given canonical meshes into distributed latent object representations \(Z\),
              which consists of \(N\) representative points \(p\), associated bounding spheres with radii \(r\), and local latent vectors \(z\).
            </p>
            <div class="publication-video">
              <div id="object-viewer">
                <div id="orig-view" class="mesh-view"></div>
                <div id="sphere-view" class="mesh-view"></div>
                <div id="latent-view" class="mesh-view"></div>
                <div id="points-view" class="mesh-view"></div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container is-centered has-text-centered">
        <h2 class="title is-4">Broad Phase</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths has-text-justified">
            <p>
              In the broad phase stage, we transform the spheres along the trajectory to find the time and pair of spheres that intersect.
            </p>
            <br/>
            <div class="publication-video" id="ccd-viewer">
            </div>
            <script type="module" src="./src/robot_motion.js"></script>
            <script type="module" src="./src/object_viewer.js"></script>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-centered has-text-centered">
        <h2 class="title is-4">Narrow Phase</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths has-text-justified">
            <p>
              In the narrow phase stage, collision decoder on pairs whose corresponding spheres are in collision, supplying the corresponding locally linearized trajectory segment.
              This allows us to limit the decoder's input to these relevant trajectory segments and local shapes rather than complete trajectories and global shapes.            </p>
            <div class="publication-video">
            </div>
          </div>
        </div>
      </div>
    </div>
  </section> -->

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-centered has-text-centered">
        <h2 class="title is-3">Motion Planning Results</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video id="video1" autoplay controls muted loop height="100%">
              <source
                src="src/videos/dish.mp4"
                type="video/mp4"
              >
            </video>
          </div>
          <div class=f"item item-video2">
            <video id="video2" autoplay controls muted loop height="100%">
              <source
                src="src/videos/bimanual.mp4"
                type="video/mp4"
              >
            </video>
          </div>
          <div class="item item-video3">
            <video id="video3" autoplay controls muted loop height="100%">
              <source
                src="src/videos/mining_site.mp4"
                type="video/mp4"
              >
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
</body>
